<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Kernel tuner : A simple CUDA kernel tuner in Python">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Kernel tuner</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/benvanwerkhoven/kernel_tuner">View on GitHub</a>

          <h1 id="project_title">Kernel tuner</h1>
          <h2 id="project_tagline">A simple CUDA kernel tuner in Python</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/benvanwerkhoven/kernel_tuner/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/benvanwerkhoven/kernel_tuner/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a id="a-simple-cudaopencl-kernel-tuner-in-python" class="anchor" href="#a-simple-cudaopencl-kernel-tuner-in-python" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>A simple CUDA/OpenCL kernel tuner in Python</h1>

<p><a href="https://travis-ci.org/benvanwerkhoven/kernel_tuner"><img src="https://api.travis-ci.org/benvanwerkhoven/kernel_tuner.svg?branch=master" alt="Build Status"></a>
<a href="https://www.codacy.com/app/b-vanwerkhoven/kernel_tuner"><img src="https://api.codacy.com/project/badge/grade/016dc85044ab4d57b777449d93275608" alt="Codacy Badge"></a>
<a href="https://www.codacy.com/app/b-vanwerkhoven/kernel_tuner"><img src="https://api.codacy.com/project/badge/coverage/016dc85044ab4d57b777449d93275608" alt="Codacy Badge"></a></p>

<p>The goal of this project is to provide a - as simple as possible - tool 
for tuning CUDA and OpenCL kernels. This implies that any CUDA or OpenCL 
kernel can be tuned without requiring extensive changes to the original 
kernel code.</p>

<p>A very common problem in GPU programming is that some combination of 
thread block dimensions and other kernel parameters, like tiling or 
unrolling factors, results in dramatically better performance than other 
kernel configurations. The goal of auto-tuning is to automate the 
process of finding the best performing configuration for a given device.</p>

<p>This kernel tuner aims that you can directly use the tuned kernel
without introducing any new dependencies. The tuned kernels can
afterwards be used independently of the programming environment, whether
that is using C/C++/Java/Fortran or Python doesn't matter.</p>

<p>The kernel_tuner module currently only contains main one function which
is called tune_kernel to which you pass at least the kernel name, a string
containing the kernel code, the problem size, a list of kernel function
arguments, and a dictionary of tunable parameters. There are also a lot
of optional parameters, for a complete list see the full documentation of
<a href="http://benvanwerkhoven.github.io/kernel_tuner/sphinxdoc/html/details.html">tune_kernel</a>.</p>

<h2>
<a id="documentation" class="anchor" href="#documentation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

<p>The full documentation is available <a href="http://benvanwerkhoven.github.io/kernel_tuner/sphinxdoc/html/index.html">here</a>.</p>

<h2>
<a id="installation" class="anchor" href="#installation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

<p>clone the repository<br>
    <code>git clone git@github.com:benvanwerkhoven/kernel_tuner.git</code><br>
change into the top-level directory<br>
    <code>cd kernel_tuner</code><br>
install using<br>
    <code>pip install .</code></p>

<h2>
<a id="dependencies" class="anchor" href="#dependencies" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h2>

<ul>
<li>Python 2.7 or Python 3.5</li>
<li>PyCuda and/or PyOpenCL (<a href="https://mathema.tician.de/software/">https://mathema.tician.de/software/</a>)</li>
</ul>

<h2>
<a id="example-usage" class="anchor" href="#example-usage" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Example usage</h2>

<p>The following shows a simple example use of the kernel tuner:</p>

<div class="highlight highlight-source-python"><pre>kernel_string <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"""</span></span>
<span class="pl-s">__global__ void vector_add(float *c, float *a, float *b, int n) {</span>
<span class="pl-s">    int i = blockIdx.x * block_size_x + threadIdx.x;</span>
<span class="pl-s">    if (i&lt;n) {</span>
<span class="pl-s">        c[i] = a[i] + b[i];</span>
<span class="pl-s">    }</span>
<span class="pl-s">}</span>
<span class="pl-s"><span class="pl-pds">"""</span></span>

size <span class="pl-k">=</span> <span class="pl-c1">10000000</span>
problem_size <span class="pl-k">=</span> (size, <span class="pl-c1">1</span>)

a <span class="pl-k">=</span> numpy.random.randn(size).astype(numpy.float32)
b <span class="pl-k">=</span> numpy.random.randn(size).astype(numpy.float32)
c <span class="pl-k">=</span> numpy.zeros_like(b)
n <span class="pl-k">=</span> numpy.int32(size)
args <span class="pl-k">=</span> [c, a, b, n]

tune_params <span class="pl-k">=</span> <span class="pl-c1">dict</span>()
tune_params[<span class="pl-s"><span class="pl-pds">"</span>block_size_x<span class="pl-pds">"</span></span>] <span class="pl-k">=</span> [<span class="pl-c1">128</span><span class="pl-k">+</span><span class="pl-c1">64</span><span class="pl-k">*</span>i <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">range</span>(<span class="pl-c1">15</span>)]

tune_kernel(<span class="pl-s"><span class="pl-pds">"</span>vector_add<span class="pl-pds">"</span></span>, kernel_string, problem_size, args, tune_params)</pre></div>

<p>And for OpenCL:</p>

<div class="highlight highlight-source-python"><pre>kernel_string <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"""</span></span>
<span class="pl-s">__kernel void vector_add(__global float *c, __global float *a, __global float *b, int n) {</span>
<span class="pl-s">    int i = get_global_id(0);</span>
<span class="pl-s">    if (i&lt;n) {</span>
<span class="pl-s">        c[i] = a[i] + b[i];</span>
<span class="pl-s">    }</span>
<span class="pl-s">}</span>
<span class="pl-s"><span class="pl-pds">"""</span></span>

size <span class="pl-k">=</span> <span class="pl-c1">10000000</span>
problem_size <span class="pl-k">=</span> (size, <span class="pl-c1">1</span>)

a <span class="pl-k">=</span> numpy.random.rand(size).astype(numpy.float32)
b <span class="pl-k">=</span> numpy.random.rand(size).astype(numpy.float32)
c <span class="pl-k">=</span> numpy.zeros_like(a)
n <span class="pl-k">=</span> numpy.int32(size)

args <span class="pl-k">=</span> [c, a, b, n]

tune_params <span class="pl-k">=</span> <span class="pl-c1">dict</span>()
tune_params[<span class="pl-s"><span class="pl-pds">"</span>block_size_x<span class="pl-pds">"</span></span>] <span class="pl-k">=</span> [<span class="pl-c1">128</span><span class="pl-k">+</span><span class="pl-c1">64</span><span class="pl-k">*</span>i <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">range</span>(<span class="pl-c1">15</span>)]

tune_kernel(<span class="pl-s"><span class="pl-pds">"</span>vector_add<span class="pl-pds">"</span></span>, kernel_string, problem_size, args, tune_params)
</pre></div>

<p>More extensive examples are available in the <code>examples</code> directory and in the <a href="http://benvanwerkhoven.github.io/kernel_tuner/sphinxdoc/html/index.html">full documentation</a>.</p>

<h2>
<a id="contribution-guide" class="anchor" href="#contribution-guide" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contribution guide</h2>

<p>The kernel tuner follows the Google Python style guide, with Sphinxdoc docstrings for module public functions. If you want to
contribute to the project please fork it, create a branch including your addition, and create a pull request.</p>

<p>The tests use relative imports and can be run directly after making
changes to the code. To run all tests use <code>nosetests</code> in the main directory.
To run the examples after code changes, you need to run <code>pip install --upgrade .</code> in the main directory.
Documentation is generated by typing <code>make html</code> in the doc directory, the contents
of <code>doc/build/html/</code> should then be copied to <code>sphinxdoc</code> directory of the <code>gh-pages</code> branch.</p>

<p>Before creating a pull request please ensure the following:</p>

<ul>
<li>You have written unit tests to test your additions</li>
<li>All unit tests pass</li>
<li>The examples still work and produce the same (or better) results</li>
<li>The code is compatible with both Python 2.7 and Python 3.5</li>
<li>An entry about the change or addition is created in CHANGELOG.md</li>
</ul>

<p>Contributing authors so far:</p>

<ul>
<li>Ben van Werkhoven</li>
<li>Berend Weel</li>
</ul>

<h2>
<a id="related-work" class="anchor" href="#related-work" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Related work</h2>

<p>You may also like <a href="https://github.com/CNugteren/CLTune">CLTune</a> by Cedric
Nugteren. CLTune is a C++ library for kernel tuning and supports various
advanced features like machine learning to optimize the time spent on tuning
kernels.</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Kernel tuner maintained by <a href="https://github.com/benvanwerkhoven">benvanwerkhoven</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
