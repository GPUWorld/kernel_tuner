

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Detailed documentation &mdash; kernel_tuner 0.0.1 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="kernel_tuner 0.0.1 documentation" href="index.html"/>
        <link rel="next" title="Application Examples" href="examples.html"/>
        <link rel="prev" title="The kernel_tuner documentation" href="index.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> kernel_tuner
          

          
          </a>

          
            
            
              <div class="version">
                0.0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Introduction</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Detailed documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Application Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="features.html">Feature Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="internal.html">Internal documentation</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">kernel_tuner</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Detailed documentation</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/details.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="toctree-wrapper compound">
<ul class="simple">
</ul>
</div>
<div class="section" id="detailed-documentation">
<h1>Detailed documentation<a class="headerlink" href="#detailed-documentation" title="Permalink to this headline">¶</a></h1>
<p>This file provides detailed information of how the kernel tuner can be
called including all the optional arguments.</p>
<dl class="function">
<dt id="kernel_tuner.tune_kernel">
<code class="descclassname">kernel_tuner.</code><code class="descname">tune_kernel</code><span class="sig-paren">(</span><em>kernel_name</em>, <em>kernel_string</em>, <em>problem_size</em>, <em>arguments</em>, <em>tune_params</em>, <em>grid_div_x=None</em>, <em>grid_div_y=None</em>, <em>restrictions=None</em>, <em>answer=None</em>, <em>verbose=False</em>, <em>lang=None</em>, <em>device=0</em>, <em>cmem_args=None</em><span class="sig-paren">)</span><a class="headerlink" href="#kernel_tuner.tune_kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Tune a CUDA kernel given a set of tunable parameters</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>kernel_name</strong> (<em>string</em>) &#8211; The name of the kernel in the code.</li>
<li><strong>kernel_string</strong> (<em>string</em>) &#8211; The CUDA, OpenCL, or C kernel code as a string.</li>
<li><strong>problem_size</strong> (<em>tuple(int, int)</em>) &#8211; A tuple containing the size from which the grid
dimensions of the kernel will be computed. Do not divide by
the thread block sizes, if this is necessary use grid_div_x/y to
specify.</li>
<li><strong>arguments</strong> (<em>list</em>) &#8211; A list of kernel arguments, use numpy arrays for
arrays, use numpy.int32 or numpy.float32 for scalars.</li>
<li><strong>tune_params</strong> (<em>dict( string : [...] )</em>) &#8211; <p>A dictionary containing the parameter names as keys,
and lists of possible parameter settings as values.
The kernel tuner will try to compile and benchmark all possible
combinations of all possible values for all tuning parameters.
This typically results in a rather large search space of all
possible kernel configurations.
For each kernel configuration, each tuning parameter is
replaced at compile-time with its current value.
Currently, the kernel tuner uses the convention that the following
list of tuning parameters are used as thread block dimensions:</p>
<blockquote>
<div><ul>
<li>&#8220;block_size_x&#8221;   thread block (work group) x-dimension</li>
<li>&#8220;block_size_y&#8221;   thread block (work group) y-dimension</li>
<li>&#8220;block_size_z&#8221;   thread block (work group) z-dimension</li>
</ul>
</div></blockquote>
<p>Options for changing these defaults may be added later. If you
don&#8217;t want the thread block dimensions to be compiled in, you
may use the built-in variables blockDim.xyz in CUDA or the
built-in function get_local_size() in OpenCL instead.</p>
</li>
<li><strong>grid_div_x</strong> (<em>list</em>) &#8211; A list of names of the parameters whose values divide
the grid dimensions in the x-direction. Arithmetic expressions can be
used if necessary inside the string containing a parameter name. For
example, in some cases you may want to divide the problem size in the
x-dimension with the number of warps rather than the number of threads
in a block, in such cases one could use [&#8220;block_size_x/32&#8221;]. Note that
the product of all grid divisor expressions is computed before dividing
the problem_size in that dimension. Also note that the divison is treated
as a float divison and resulting grid dimensions will be rounded up to
the nearest integer number.
If not supplied, [&#8220;block_size_x&#8221;] will be used by default, if you do not
want any grid x-dimension divisors pass an empty list.</li>
<li><strong>grid_div_y</strong> (<em>list</em>) &#8211; A list of names of the parameters whose values divide
the grid dimensions in the y-direction, None by default. See grid_div_x
for more details.</li>
<li><strong>restrictions</strong> (<em>list</em>) &#8211; A list of strings containing boolean expression that
limited the search space in that they must be satisfied by the kernel
configuration. These expressions must be true for the configuration
to be part of the search space. For example:
restrictions=[&#8220;block_size_x==block_size_y*tile_size_y&#8221;] limits the
search to configurations where the block_size_x equals the product
of block_size_y and tile_size_y.
The default is None.</li>
<li><strong>answer</strong> (<em>list</em>) &#8211; A list of arguments, similar to what you pass to arguments,
that contains the expected output of the kernel after it has executed
and contains None for each argument that is input-only. The expected
output of the kernel will then be used to verify the correctness of
each kernel in the parameter space before it will be benchmarked.</li>
<li><strong>verbose</strong> (<em>boolean</em>) &#8211; <p>Sets whether or not to report about configurations that
were skipped during the search. This could be due to several reasons:</p>
<blockquote>
<div><ul>
<li>kernel configuration fails one or more restrictions</li>
<li>too many threads per thread block</li>
<li>too much shared memory used by the kernel</li>
<li>too many resources requested for launch</li>
</ul>
</div></blockquote>
<p>verbose is set to False by default.</p>
</li>
<li><strong>lang</strong> (<em>string</em>) &#8211; Specifies the language used for GPU kernels. The kernel_tuner
automatically detects the language, but if it fails, you may specify
the language using this argument, currently supported: &#8220;CUDA&#8221;, &#8220;OpenCL&#8221;, or &#8220;C&#8221;</li>
<li><strong>device</strong> (<em>int</em>) &#8211; CUDA/OpenCL device to use, in case you have multiple
CUDA-capable GPUs or OpenCL devices you may use this to select one,
0 by default. Ignored, if you are tuning host code by passing lang=&#8221;C&#8221;.</li>
<li><strong>cmem_args</strong> (<em>dict(string: numpy object)</em>) &#8211; CUDA-specific feature for specifying constant memory
arguments to the kernel. In OpenCL these are handled as normal
kernel arguments, but in CUDA you can copy to a symbol. The way you
specify constant memory arguments is by passing a dictionary with
strings containing the constant memory symbol name together with numpy
objects in the same way as normal kernel arguments.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A dictionary of all executed kernel configurations and their
execution times.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">dict( string, float )</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="kernel_tuner.run_kernel">
<code class="descclassname">kernel_tuner.</code><code class="descname">run_kernel</code><span class="sig-paren">(</span><em>kernel_name</em>, <em>kernel_string</em>, <em>problem_size</em>, <em>arguments</em>, <em>params</em>, <em>grid_div_x=None</em>, <em>grid_div_y=None</em>, <em>lang=None</em>, <em>device=0</em>, <em>cmem_args=None</em><span class="sig-paren">)</span><a class="headerlink" href="#kernel_tuner.run_kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Compile and run a single kernel</p>
<p>Compiles and runs a single kernel once, given a specific instance of the kernels tuning parameters.
This function was added to the kernel tuner mostly for verifying kernel correctness.
On purpose, it is called much in the same way as <cite>tune_kernel()</cite></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>kernel_name</strong> (<em>string</em>) &#8211; The name of the kernel in the code</li>
<li><strong>kernel_string</strong> (<em>string</em>) &#8211; The CUDA or OpenCL kernel code as a string</li>
<li><strong>problem_size</strong> (<em>tuple(int, int)</em>) &#8211; A tuple containing the size from which the grid
dimensions of the kernel will be computed. Do not divide by
the thread block sizes, if this is necessary use grid_div_x/y to
specify.</li>
<li><strong>arguments</strong> (<em>list</em>) &#8211; A list of kernel arguments, use numpy arrays for
arrays, use numpy.int32 or numpy.float32 for singulars</li>
<li><strong>params</strong> (<em>dict( string: int )</em>) &#8211; A dictionary containing the tuning parameter names as keys
and a single value per tuning parameter as values.</li>
<li><strong>grid_div_x</strong> (<em>list</em>) &#8211; See tune_kernel()</li>
<li><strong>grid_div_y</strong> (<em>list</em>) &#8211; See tune_kernel()</li>
<li><strong>lang</strong> (<em>string</em>) &#8211; Language of the kernel, supply &#8220;CUDA&#8221;, &#8220;OpenCL&#8221;, or &#8220;C&#8221; if not detected automatically.</li>
<li><strong>device</strong> (<em>int</em>) &#8211; CUDA/OpenCL device to use, 0 by default.</li>
<li><strong>cmem_args</strong> (<em>dict(string, ...)</em>) &#8211; CUDA-specific feature for specifying constant memory
arguments to the kernel. See tune_kernel() for details.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A list of numpy arrays, similar to the arguments passed to this
function, containing the output after kernel execution.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">list</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="examples.html" class="btn btn-neutral float-right" title="Application Examples" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="The kernel_tuner documentation" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Ben van Werkhoven.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.0.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>